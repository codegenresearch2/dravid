import asyncio\"nimport sys\"nimport time\"nfrom ..api.main import call_dravid_api_with_pagination\"nfrom ..utils.parser import extract_and_parse_xml\"nfrom ..prompts.file_metada_desc_prompts import get_file_metadata_prompt\"nfrom ..utils.utils import print_info, print_error, print_success, print_warning\"n\"nMAX_CONCURRENT_REQUESTS = 10\"nMAX_CALLS_PER_MINUTE = 100\"nRATE_LIMIT_PERIOD = 60 # seconds\"n\"nclass RateLimiter:\"n    def __init__(self, max_calls, period):\"n        self.max_calls = max_calls\"n        self.period = period\"n        self.calls = asyncio.Queue(maxsize=max_calls)\"n        self.semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\"n\"n    async def acquire(self):\"n        while True:\"n            if self.calls.full():\"n                oldest_call = await self.calls.get()\"n                time_since_oldest_call = time.time() - oldest_call\"n                if time_since_oldest_call < self.period:\"n                    await asyncio.sleep(self.period - time_since_oldest_call)\"n            await self.calls.put(time.time())\"n            return\"n\"nrate_limiter = RateLimiter(MAX_CALLS_PER_MINUTE, RATE_LIMIT_PERIOD)\"n\"ndef to_thread(func, *args, **kwargs):\"n    if sys.version_info >= (3, 9):\"n        return asyncio.to_thread(func, *args, **kwargs)\"n    else:\"n        loop = asyncio.get_event_loop()\"n        return loop.run_in_executor(None, functools.partial(func, *args, **kwargs))\"n\"nasync def process_single_file(filename, content, project_context, folder_structure):\"n    metadata_query = get_file_metadata_prompt(filename, content, project_context, folder_structure)\"n    try:\"n        async with rate_limiter.semaphore:\"n            await rate_limiter.acquire()\"n            response = await to_thread(call_dravid_api_with_pagination, metadata_query, include_context=True)\"n\n        root = extract_and_parse_xml(response)\"n        type_elem = root.find('.//type')\"n        summary_elem = root.find('.//summary')  # Added summary element\"n        exports_elem = root.find('.//exports')\"n        imports_elem = root.find('.//imports')  # Added imports element\"n\n        file_type = type_elem.text.strip() if type_elem is not None and type_elem.text else "unknown"\"n        summary = summary_elem.text.strip() if summary_elem is not None and summary_elem.text else "No summary available"\"n        exports = exports_elem.text.strip() if exports_elem is not None and exports_elem.text else ""\"n        imports = imports_elem.text.strip() if imports_elem is not None and imports_elem.text else ""\"n\n        print_success(f"Processed: {filename}")\"n        return filename, file_type, summary, exports, imports  # Return imports\"n    except Exception as e:\"n        print_error(f"Error processing {filename}: {e}")\"n        return filename, "unknown", f"Error: {e}", "", ""  # Return empty imports on error\"n\"nasync def process_files(files, project_context, folder_structure):\"n    total_files = len(files)\"n    print_info(f"Processing {total_files} files to construct metadata per file")\"n    print_info(f"LLM calls to be made: {total_files}")\"n\n    async def process_batch(batch):\"n        tasks = [process_single_file(filename, content, project_context, folder_structure)\"n                 for filename, content in batch]\"n        return await asyncio.gather(*tasks)\"n\n    batch_size = MAX_CONCURRENT_REQUESTS\"n    results = []\"n    for i in range(0, total_files, batch_size):\"n        batch = files[i:i+batch_size]\"n        batch_results = await process_batch(batch)\"n        results.extend(batch_results)\"n        print_info(f"Progress: {len(results)}/{total_files} files processed")\"n\n    return results\"n